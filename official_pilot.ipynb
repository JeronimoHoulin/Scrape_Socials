{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a10757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8d67c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp/ipykernel_6892/678387388.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n"
     ]
    }
   ],
   "source": [
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(PATH)\n",
    "\n",
    "#Making the URLs for the get function\n",
    "#tweet_fields = \"tweet.fields=created_at,source,text,public_metrics,author_id\"\n",
    "#query = \"%40solana%20and%20ido%20-is%3aretweet\"\n",
    "#url1 = \"https://twitter.com/search?query={}&{}\".format(query, tweet_fields)\n",
    "\n",
    "## Or search by Username\n",
    "url2 = 'https://twitter.com/google'\n",
    "driver.get(url2)\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d2d7063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp/ipykernel_6892/656036678.py:2: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  cards = driver.find_elements_by_css_selector(\"article\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet fijado\n",
      "Google\n",
      "@Google\n",
      "·\n",
      "18 ene.\n",
      "#DoodleForGoogle is back, and this year Rare Impact Fund founder \n",
      "@SelenaGomez\n",
      " is joining our judges panel. This year's theme is \"I care for myself by...\" and we can't wait to see your submissions! Learn more and enter today → http://goo.gle/D4G223\n",
      "301\n",
      "1,2 mil\n",
      "5,8 mil\n",
      "Google\n",
      "@Google\n",
      "·\n",
      "17h\n",
      "¡Nuevas oportunidades llegando! Nuestros Certificados de carrera de Google ahora apoyan a personas de habla hispana para análisis de datos, gestión de proyectos y diseño de UX, además de soporte de TI http://goo.gle/certificates-es #GrowWithGoogle\n",
      "13\n",
      "36\n",
      "244\n",
      "Mostrar este hilo\n"
     ]
    }
   ],
   "source": [
    "#cards = driver.find_elements('//div[@data-testid=\"tweet\"]')\n",
    "cards = driver.find_elements_by_css_selector(\"article\")\n",
    "#cards = driver.find_elements_by_xpath('//div[@class=\"css-1dbjc4n r-18u37iz\"]')\n",
    "#print(cards)\n",
    "for card in cards:\n",
    "    print(card.text)\n",
    "    #print(type(card.text))\n",
    "    #all cards here are formated as single str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "003edf46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Google\n",
      "---------------\n",
      "¡Nuevas oportunidades llegando! Nuestros Certificados de carrera de Google ahora apoyan a personas de habla hispana para análisis de datos, gestión de proyectos y diseño de UX, además de soporte de TI http://goo.gle/certificates-es #GrowWithGoogle\n",
      "---------------\n",
      "2022-01-24T17:35:15.000Z\n",
      "---------------\n",
      "\n",
      "---------------\n",
      "13\n",
      "---------------\n",
      "36\n",
      "---------------\n",
      "244\n"
     ]
    }
   ],
   "source": [
    "#Selecting first card to format it\n",
    "card = cards[1]\n",
    "#print(card)\n",
    "#Copy paste the FULL X-Path and run since article with: \"./\"\n",
    "text = card.find_element_by_xpath('./div/div/div/div[2]/div[2]/div[2]/div[1]').text\n",
    "responding = card.find_element_by_xpath('./div/div/div/div[2]/div[2]/div[2]/div[2]').text\n",
    "handle = card.find_element_by_xpath('.//*[contains(text(),\"@\")]').text\n",
    "date = card.find_element_by_xpath('.//time').get_attribute('datetime')\n",
    "replies = card.find_element_by_xpath('.//div[@data-testid=\"reply\"]').text\n",
    "retweets = card.find_element_by_xpath('.//div[@data-testid=\"retweet\"]').text\n",
    "likes = card.find_element_by_xpath('.//div[@data-testid=\"like\"]').text\n",
    "\n",
    "print(handle)\n",
    "print(\"---------------\")\n",
    "print(text)\n",
    "print(\"---------------\")\n",
    "print(date)\n",
    "print(\"---------------\")\n",
    "print(responding)\n",
    "print(\"---------------\")\n",
    "print(replies)\n",
    "print(\"---------------\")\n",
    "print(retweets)\n",
    "print(\"---------------\")\n",
    "print(likes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c4ad366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-01-18 19:42:39\n",
      "<class 'datetime.datetime'>\n",
      "2022-01-24 17:35:15\n",
      "<class 'datetime.datetime'>\n"
     ]
    }
   ],
   "source": [
    "for card in cards: \n",
    "    #GET FULL XPATH AND FOLLOW THROUGH AFTER TAG \"ARTICLE\"\n",
    "    text = card.find_element_by_xpath('./div/div/div/div[2]/div[2]/div[2]/div[1]').text\n",
    "    handle = card.find_element_by_xpath('.//*[contains(text(),\"@\")]').text\n",
    "    date = card.find_element_by_xpath('.//time').get_attribute('datetime')\n",
    "    \n",
    "    \"\"\"STR date into python datetime object\"\"\"\n",
    "    date = date.rstrip(\".000Z\")\n",
    "    date = date.replace(\"T\", \" \")\n",
    "    date = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    print(date)\n",
    "    print(type(date))\n",
    "    \"\"\"\n",
    "    fullstring = text\n",
    "    substring_list = [\"#NFT\", \"#nft\"]\n",
    "\n",
    "    if any(substring in fullstring for substring in substring_list):\n",
    "        #print(\"Found!\")\n",
    "        print(handle)\n",
    "        print(\"---------------\")\n",
    "        print(text)\n",
    "    else:\n",
    "        print(\"Not found!\")\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f59c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a function: \n",
    "def get_tweet_data(card):\n",
    "    #Elements\n",
    "    #GET FULL XPATH AND FOLLOW THROUGH AFTER TAG \"ARTICLE\"\n",
    "    text = card.find_element_by_xpath('./div/div/div/div[2]/div[2]/div[2]/div[1]').text\n",
    "    responding = card.find_element_by_xpath('./div/div/div/div[2]/div[2]/div[2]/div[2]').text\n",
    "    handle = card.find_element_by_xpath('.//*[contains(text(),\"@\")]').text\n",
    "    replies = card.find_element_by_xpath('.//div[@data-testid=\"reply\"]').text\n",
    "    retweets = card.find_element_by_xpath('.//div[@data-testid=\"retweet\"]').text\n",
    "    likes = card.find_element_by_xpath('.//div[@data-testid=\"like\"]').text\n",
    "    full_txt = text+responding\n",
    "    \n",
    "    #Sponsored tweets have no date\n",
    "    try: \n",
    "        date = card.find_element_by_xpath('.//time').get_attribute('datetime')\n",
    "    except NoSuchElementException: \n",
    "        return\n",
    "    \n",
    "    #Create a tuple for the tweet\n",
    "    tweet = (handle, full_txt, date)\n",
    "    \n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c98a03d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'WebElement' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8620/2298109985.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#First try\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mget_tweet_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcard\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcard\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'WebElement' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#First try\n",
    "get_tweet_data(card)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28ef7b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All data\n",
    "tweet_data = []\n",
    "for card in cards: \n",
    "    data = get_tweet_data(card) \n",
    "    tweet_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3fd1356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "tweet_data\n",
    "print(type(tweet_data[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df96a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrolling down the page\n",
    "#Need's some JS\n",
    "driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4cfc612",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp/ipykernel_8396/1680588977.py:33: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp/ipykernel_8396/1680588977.py:54: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  cards = driver.find_elements_by_css_selector(\"article\")\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Make Everything Happend In Sync\"\"\"\n",
    "#Imports\n",
    "import time \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "#Defining functions\n",
    "def get_tweet_data(card):\n",
    "    #Elements\n",
    "    #GET FULL XPATH AND FOLLOW THROUGH AFTER TAG \"ARTICLE\"\n",
    "    text = card.find_element_by_xpath('./div/div/div/div[2]/div[2]/div[2]/div[1]').text\n",
    "    responding = card.find_element_by_xpath('./div/div/div/div[2]/div[2]/div[2]/div[2]').text\n",
    "    handle = card.find_element_by_xpath('.//*[contains(text(),\"@\")]').text\n",
    "    replies = card.find_element_by_xpath('.//div[@data-testid=\"reply\"]').text\n",
    "    retweets = card.find_element_by_xpath('.//div[@data-testid=\"retweet\"]').text\n",
    "    likes = card.find_element_by_xpath('.//div[@data-testid=\"like\"]').text\n",
    "    full_txt = text+responding\n",
    "    \n",
    "    \"\"\"STR date into python datetime object\"\"\"\n",
    "    date = date.rstrip(\".000Z\")\n",
    "    date = date.replace(\"T\", \" \")\n",
    "    date = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "    \n",
    "    \n",
    "    #Sponsored tweets have no date\n",
    "    try: \n",
    "        date = card.find_element_by_xpath('.//time').get_attribute('datetime')\n",
    "    except NoSuchElementException: \n",
    "        return\n",
    "    \n",
    "    #Create a tuple for the tweet\n",
    "    tweet = (handle, full_txt, date)\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "#Creating an instance of a webdriver\n",
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(PATH)\n",
    "\n",
    "#Making the URLs for the get function\n",
    "#tweet_fields = \"tweet.fields=created_at,source,text,public_metrics,author_id\"\n",
    "#query = \"%40solana%20and%20ido%20-is%3aretweet\"\n",
    "#url1 = \"https://twitter.com/search?query={}&{}\".format(query, tweet_fields)\n",
    "\n",
    "## Or search by Username\n",
    "url2 = 'https://twitter.com/IDOhunteer'\n",
    "driver.get(url2)\n",
    "time.sleep(10)\n",
    "\n",
    "#Create tweet ID's for already scraped tweets\n",
    "tweet_ids = set()\n",
    "tweet_data = []\n",
    "\n",
    "#Check if I'm at the end of the page\n",
    "last_pos = driver.execute_script('return window.pageYOFFset;')\n",
    "\n",
    "#Looping through tweets\n",
    "while True:\n",
    "    cards = driver.find_elements_by_css_selector(\"article\")\n",
    "    for card in cards[-15:]: \n",
    "        tweet = get_tweet_data(card) \n",
    "        \n",
    "        tweet_id = ''.join(tweet)\n",
    "        if tweet_id not in tweet_ids:\n",
    "            tweet_ids.add(tweet_id)\n",
    "            tweet_data.append(tweet)\n",
    "            \n",
    "    #Finally adding pagination\n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "    time.sleep(1)\n",
    "\n",
    "    #Current position and comparison to check if I'm at the bottom\n",
    "    curr_pos = driver.execute_script('return window.pageYOFFset;')\n",
    "    if last_pos == curr_pos: \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1220d7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@IDOhunteer',\n",
       "  \"WUMWE4N2SafePal - Crypto Wallet\\n@iSafePal\\n · 12 ene.\\n's 1st @iSafePal Giftbox Learn & Earn Event\\n\\nIntroducing @yokaiswap 1st LaunchPad Project @Daruma_DAO \\n\\nMore info on @iSafePal Giftbox https://blog.safepal.io/introducing-safepal-giftbox/…\\n\\nDownload @iSafePal App Today \\nhttps://safepal.io/download\",\n",
       "  '2022-01-13T01:42:55.000Z'),\n",
       " ('@iSafePal',\n",
       "  \"'s 1st \\n@iSafePal\\n Giftbox Learn & Earn Event\\n\\nIntroducing \\n@yokaiswap\\n 1st LaunchPad Project \\n@Daruma_DAO\\n \\n\\nMore info on \\n@iSafePal\\n Giftbox https://blog.safepal.io/introducing-safepal-giftbox/…\\n\\nDownload \\n@iSafePal\\n App Today \\nhttps://safepal.io/download\",\n",
       "  '2022-01-13T00:40:46.000Z'),\n",
       " ('@DefiLlama',\n",
       "  'Now tracking \\n@SentreProtocol\\n on \\n@solana\\n \\n\\nAn on-chain AMM powering the evolution of DeFi.\\n\\nhttps://defillama.com/protocol/sentre',\n",
       "  '2022-01-05T23:49:19.000Z')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7af8f5ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\AppData\\Local\\Temp/ipykernel_6892/4045488357.py:12: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH)\n",
      "C:\\Users\\Usuario\\AppData\\Local\\Temp/ipykernel_6892/4045488357.py:93: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  cards = driver.find_elements_by_css_selector(\"article\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1^st Attempt to scroll. Break in 3rd.\n",
      "1^st Attempt to scroll. Break in 3rd.\n",
      "2^st Attempt to scroll. Break in 3rd.\n",
      "---------------------------------------------------\n",
      "Amount of tweets collected: 2\n",
      "---------------------------------------------------\n",
      "---------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Imports\"\"\"\n",
    "import time \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n",
    "\n",
    "#Creating an instance of a webdriver\n",
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(PATH)\n",
    "\n",
    "\n",
    "\"\"\" Variables \"\"\"\n",
    "#Making the URLs for the get function\n",
    "#tweet_fields = \"tweet.fields=created_at,source,text,public_metrics,author_id\"\n",
    "#query = \"%40solana%20and%20ido%20-is%3aretweet\"\n",
    "#url1 = \"https://twitter.com/search?query={}&{}\".format(query, tweet_fields)\n",
    "#Or the url itself (for searched items)\n",
    "\n",
    "url1 = \"https://twitter.com/search?q=%23ido%20AND%20%23solana&src=typed_query\"\n",
    "url2 = \"https://twitter.com/search?q=%23ido%20AND%20%23solana&src=typed_query&f=live\"\n",
    "## Or search by Username\n",
    "url3 = 'https://twitter.com/thexastronaut'\n",
    "\n",
    "#Set other parameters: \n",
    "stringy = \"upcoming\"\n",
    "\n",
    "#GENERATE THE REQUEST !\n",
    "driver.get(url3)\n",
    "time.sleep(20)\n",
    "\n",
    "\n",
    "\"\"\" Function \"\"\"\n",
    "def get_tweet_data(card):\n",
    "    \n",
    "    try:\n",
    "        #Elements\n",
    "        #GET FULL XPATH AND FOLLOW THROUGH AFTER TAG \"ARTICLE\" \n",
    "        text = card.find_element_by_xpath('./div/div/div/div[2]/div[2]/div[2]/div[1]').text\n",
    "        responding = card.find_element_by_xpath('./div/div/div/div[2]/div[2]/div[2]/div[2]').text\n",
    "        handle = card.find_element_by_xpath('.//*[contains(text(),\"@\")]').text\n",
    "        #replies = card.find_element_by_xpath('.//div[@data-testid=\"reply\"]').text\n",
    "        #retweets = card.find_element_by_xpath('.//div[@data-testid=\"retweet\"]').text\n",
    "        #likes = card.find_element_by_xpath('.//div[@data-testid=\"like\"]').text\n",
    "        full_txt = text+responding\n",
    "        \n",
    "        #Only add tweets w/ contains variable\n",
    "        if stringy in text:\n",
    "\n",
    "            #Sponsored tweets have no date\n",
    "            try: \n",
    "                date = card.find_element_by_xpath('.//time').get_attribute('datetime')\n",
    "                \n",
    "            except NoSuchElementException: \n",
    "                return\n",
    "\n",
    "            \"\"\"STR date into python datetime object\"\"\"\n",
    "            date = date.rstrip(\".000Z\")\n",
    "            date = date.replace(\"T\", \" \")\n",
    "            date_obj = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "            \n",
    "            #Only tweets before this date...\n",
    "            if date_obj > datetime(2021, 11, 1):\n",
    "\n",
    "                #Create a tuple for the tweet\n",
    "                tweet = (handle, full_txt, date)\n",
    "                return tweet\n",
    "\n",
    "    #NoSuchElement error handling\n",
    "    except NoSuchElementException:\n",
    "        pass\n",
    "    #StaleElementReferenceException error handling\n",
    "    except StaleElementReferenceException:\n",
    "        pass\n",
    "    \n",
    "\n",
    "\"\"\" Scrolling \"\"\"\n",
    "#Create tweet ID's for already scraped tweets\n",
    "tweet_ids = set()\n",
    "tweet_data = []\n",
    "\n",
    "#Check if I'm at the end of the page\n",
    "last_pos = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "#print(f'last post: {last_pos}')\n",
    "\n",
    "#Set scrolilng\n",
    "scrolling = True\n",
    "\n",
    "#Looping through tweets\n",
    "while scrolling:\n",
    "    #Define the tweet segment\n",
    "    cards = driver.find_elements_by_css_selector(\"article\")\n",
    "    \n",
    "    for card in cards: \n",
    "        tweet = get_tweet_data(card)\n",
    "        \n",
    "        if tweet:\n",
    "            tweet_id = ''.join(tweet)\n",
    "            if tweet_id not in tweet_ids:\n",
    "                \n",
    "                #Add id & data\n",
    "                tweet_ids.add(tweet_id)\n",
    "                tweet_data.append(tweet)\n",
    "                \n",
    "                \n",
    "    scrolling_attempt = 0\n",
    "    while True:\n",
    "        #Finally adding pagination\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        time.sleep(3)\n",
    "\n",
    "        #Current position and comparison to check if I'm at the bottom\n",
    "        curr_pos = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        if last_pos == curr_pos: \n",
    "            #If I scrolled and ended up in the same place //nothing loaded//\n",
    "            scrolling_attempt +=1\n",
    "            \n",
    "            #End of scroll region\n",
    "            if scrolling_attempt >= 3: \n",
    "                scrolling = False\n",
    "                break\n",
    "            else:\n",
    "                print(f'{scrolling_attempt}^st Attempt to scroll. Break in 3rd.')\n",
    "                time.sleep(10)\n",
    "        else:\n",
    "            last_pos = curr_pos\n",
    "            break\n",
    "                \n",
    "                \n",
    "\"\"\"Results\"\"\"\n",
    "print(\"---------------------------------------------------\")\n",
    "print(f'Amount of tweets collected: {len(tweet_data)}')\n",
    "print(\"---------------------------------------------------\")\n",
    "print(tweet_data)\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6827e1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@thexastronaut',\n",
       "  'PERFORMANCE IDO PROJECTS ON SOLSTER LAUNCHPAD\\n@solster_finance\\n is a ticket to diversify your #DeFi investment portfolio & access the best #crypto projects. \\n\\nCheck out their IDOs, especially upcoming IDOs \\n@GlitterFinance\\n @MetaxyMXY\\n @TheNestArcad \\n\\n#AstronautAnalytics #SolanaSolana y 7 más',\n",
       "  '2022-01-11 11:00:18'),\n",
       " ('@thexastronaut',\n",
       "  \"TOTAL PROJECTS ATH ROI RANKING ON SOLANIUM\\n\\nWill any of the 3 upcoming projects overtake \\n@CryowarDevs\\n's performance in ROI? Comment your thought below.\\n\\n#AstronautAnalytics #Solana #ATH #ROI $UNQ $MEAN $SLCUNQClub y 9 más\",\n",
       "  '2021-12-16 05:12:41')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1ddcbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
