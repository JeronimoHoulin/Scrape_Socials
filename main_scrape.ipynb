{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3506f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"For the times when you only need new tweets\n",
    "    a.k.a limit the timeframe with before_date.\"\"\"\n",
    "\"\"\"Imports\"\"\"\n",
    "import time \n",
    "from selenium import webdriver\n",
    "from datetime import datetime\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n",
    "\n",
    "#Creating an instance of a webdriver\n",
    "PATH = \"C:\\Program Files (x86)\\chromedriver.exe\"\n",
    "driver = webdriver.Chrome(PATH)\n",
    "\n",
    "\n",
    "\"\"\" Variables \"\"\"\n",
    "#Making the URLs for the get function\n",
    "#tweet_fields = \"tweet.fields=created_at,source,text,public_metrics,author_id\"\n",
    "#query = \"%40solana%20and%20ido%20-is%3aretweet\"\n",
    "#url1 = \"https://twitter.com/search?query={}&{}\".format(query, tweet_fields)\n",
    "#Or the url itself (for searched items)\n",
    "\n",
    "#url = \"https://twitter.com/search?q=%23ido%20AND%20%23solana&src=typed_query\"\n",
    "url = \"https://twitter.com/search?q=solana%20AND%20funding&src=typed_query&f=live\"\n",
    "## Or search by Username\n",
    "#url = 'https://twitter.com/IDO_calendar'\n",
    "\n",
    "#Set other parameters:\n",
    "stringys = [\"funding\", \"seed\", \"private\", \"upcoming\", \"ido\", \"fundraising\", \"hiring\"]\n",
    "before_date = datetime(2022, 2, 1)\n",
    "\n",
    "#GENERATE THE REQUEST !\n",
    "driver.get(url)\n",
    "\n",
    "#wait till load\n",
    "time.sleep(60)\n",
    "print(\"Page ready !\")\n",
    "\n",
    "#Create tweet ID's for already scraped tweets\n",
    "tweet_ids = set()\n",
    "tweet_data = []\n",
    "\n",
    "#Check if I'm at the end of the page\n",
    "last_pos = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "#print(f'last post: {last_pos}')\n",
    "\n",
    "#Set scrolilng\n",
    "scrolling = True\n",
    "in_range = True\n",
    "\n",
    "#Looping through tweets\n",
    "while scrolling:\n",
    "    #Define the tweet segment\n",
    "    cards = driver.find_elements_by_css_selector(\"article\")\n",
    "    \n",
    "    for card in cards: \n",
    "        \n",
    "        \"\"\" Function \"\"\"\n",
    "        try:\n",
    "            #Elements\n",
    "            #GET FULL XPATH AND FOLLOW THROUGH AFTER TAG \"ARTICLE\" \n",
    "            text = card.find_element_by_xpath('./div/div/div/div[2]/div[2]/div[2]/div[1]').text\n",
    "            responding = card.find_element_by_xpath('./div/div/div/div[2]/div[2]/div[2]/div[2]').text\n",
    "            handle = card.find_element_by_xpath('.//*[contains(text(),\"@\")]').text\n",
    "            #replies = card.find_element_by_xpath('.//div[@data-testid=\"reply\"]').text\n",
    "            #retweets = card.find_element_by_xpath('.//div[@data-testid=\"retweet\"]').text\n",
    "            #likes = card.find_element_by_xpath('.//div[@data-testid=\"like\"]').text\n",
    "            #pinned = card.find_element_by_xpath('./div/div/div/div[1]/div/div/div/div/div[2]/div/div/div').text\n",
    "            full_txt = text+responding\n",
    "            \n",
    "            #Sponsored tweets have no date\n",
    "            date = card.find_element_by_xpath('.//time').get_attribute('datetime')\n",
    "\n",
    "            \"\"\"STR date into python datetime object\"\"\"\n",
    "            #date = date.rstrip(\".000Z\")\n",
    "            date = date[:-5]\n",
    "            date = date.replace(\"T\", \" \")\n",
    "            date_obj = datetime.strptime(date, '%Y-%m-%d %H:%M:%S')\n",
    "            #print(date_obj)\n",
    "            \n",
    "        #NoSuchElement error handling\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        #StaleElementReferenceException error handling\n",
    "        except StaleElementReferenceException:\n",
    "            pass\n",
    "        \n",
    "        if any(s in text.lower() for s in stringys):\n",
    "        \n",
    "            if date_obj > before_date:\n",
    "                #Create a tuple for the tweet\n",
    "                tweet = (handle, date, full_txt)\n",
    "\n",
    "                #Create the tweet DF\n",
    "                tweet_id = ''.join(tweet)\n",
    "\n",
    "                #Add only tweets not already seen\n",
    "                if tweet_id not in tweet_ids:\n",
    "                    #Add id & data\n",
    "                    tweet_ids.add(tweet_id)\n",
    "                    tweet_data.append(tweet)\n",
    "            \"\"\"       \n",
    "            #This makes the bot skip pinned tweets; Because they have dates which are late...\n",
    "            if \"Tweet fijado\".lower() in pinned.lower():\n",
    "                if stringy in text:\n",
    "                    #Create a tuple for the tweet\n",
    "                    tweet = (handle, date, full_txt)\n",
    "\n",
    "                    #Create the tweet DF\n",
    "                    tweet_id = ''.join(tweet)\n",
    "\n",
    "                    #Add only tweets not already seen\n",
    "                    if tweet_id not in tweet_ids:\n",
    "                        #Add id & data\n",
    "                        tweet_ids.add(tweet_id)\n",
    "                        tweet_data.append(tweet)\n",
    "            \"\"\"\n",
    "        if date_obj < before_date:\n",
    "            scrolling = False\n",
    "            in_range = False\n",
    "            print(\"tweet out of range\")\n",
    "            break\n",
    "\n",
    "            \n",
    "    scrolling_attempt = 0\n",
    "    \n",
    "    while in_range == True:\n",
    "        #Finally adding pagination\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "        time.sleep(5)\n",
    "\n",
    "        #Current position and comparison to check if I'm at the bottom\n",
    "        curr_pos = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        if last_pos == curr_pos: \n",
    "            #If I scrolled and ended up in the same place //nothing loaded//\n",
    "            scrolling_attempt +=1\n",
    "            \n",
    "            #End of scroll region\n",
    "            if scrolling_attempt >= 3: \n",
    "                scrolling = False\n",
    "                break\n",
    "            else:\n",
    "                print(f'{scrolling_attempt}^st Attempt to scroll. Break in 3rd.')\n",
    "                time.sleep(10)\n",
    "        else:\n",
    "            last_pos = curr_pos\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "                \n",
    "\"\"\"Results\"\"\"\n",
    "print(\"---------------------------------------------------\")\n",
    "print(f'Amount of tweets collected: {len(tweet_data)}')\n",
    "print(\"---------------------------------------------------\")\n",
    "for i in tweet_data: \n",
    "    print(\"---------0---------\")\n",
    "    print(i)\n",
    "\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
